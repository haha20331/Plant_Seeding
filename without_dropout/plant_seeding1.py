# -*- coding: utf-8 -*-
"""Plant Seeding with 李弘毅

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12UA6S7clZJOhWBSByH5_RiJuurDmrCSH
"""


# Commented out IPython magic to ensure Python compatibility.
#%cd drive/MyDrive/PlantSeeding/train
# %cd drive/MyDrive/PlantSeeding/
#!ls
#!unzip train.zip

#from torchvision.datasets import ImageFolder
#image_folder = ImageFolder("./train", transform=None, target_transform=None)
#print(image_folder.class_to_idx)
path="./train"

_exp_name = "Plant_Seedng"

# Import necessary packages.
import numpy as np
import pandas as pd
import torch
import os
import torch.nn as nn
from torchvision import datasets ,models, transforms
import torchvision.transforms as transforms
# "ConcatDataset" and "Subset" are possibly useful when doing semi-supervised learning.
from torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset
from torchvision.datasets import DatasetFolder, VisionDataset
import matplotlib.pyplot as plt
# This is for the progress bar.
from tqdm.auto import tqdm
import random

#from pylab import *
myseed = 6666  # set a random seed for reproducibility
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False
np.random.seed(myseed)
torch.manual_seed(myseed)
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(myseed)

# Normally, We don't need augmentations in testing and validation.
# All we need here is to resize the PIL image and transform it into Tensor.
padding = (40, 40, 40, 40)
test_tfm = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor(),
])

# However, it is also possible to use augmentation in the testing phase.
# You may use train_tfm to produce a variety of images and then test using ensemble methods
train_tfm = transforms.Compose([
   # transforms.RandomEqualize(p=1),
   # transforms.RandomAdjustSharpness(sharpness_factor=3,p=1),
   # transforms.Grayscale(num_output_channels=3),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomVerticalFlip(p=0.5),
    transforms.RandomRotation([-180,180], expand=True),
    transforms.Resize((128,128)),
    transforms.ToTensor(),
    transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False), 
    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))
])
trainloss = []
trainacc = []
validloss = []
validacc = []
from torch import nn
class Residual_Network(nn.Module):
    def __init__(self):
        super(Residual_Network, self).__init__()
        #3*128*128
        self.cnn1 = nn.Sequential(
                nn.Conv2d(3,64,3,1,1),
                nn.ReLU(),
                nn.Conv2d(64,64,3,1,1),
                nn.ReLU(),
                nn.MaxPool2d(2,2,0),)

        self.cnn2 = nn.Sequential(
                nn.Conv2d(64,128,3,1,1),  
                nn.ReLU(),
                nn.Conv2d(128,128,3,1,1),
                nn.ReLU(),
                nn.MaxPool2d(2,2,0),)

        self.cnn3 = nn.Sequential(
                nn.Conv2d(128,256,3,1,1),
                nn.ReLU(),
                nn.Conv2d(256,256,3,1,1),
                nn.ReLU(),
                nn.Conv2d(256,256,3,1,1),
                nn.ReLU(),
                nn.MaxPool2d(2,2,0),)

        self.cnn4 = nn.Sequential(
                nn.Conv2d(256,512,3,1,1),
                nn.ReLU(),
                nn.Conv2d(512,512,3,1,1),
                nn.ReLU(),
                nn.Conv2d(512,512,3,1,1),
                nn.ReLU(),
                nn.MaxPool2d(2,2,0),)

        self.cnn5 = nn.Sequential(
                nn.Conv2d(512,512,3,1,1),
                nn.ReLU(),
                nn.Conv2d(512,512,3,1,1),
                nn.ReLU(),
                nn.Conv2d(512,512,3,1,1),
                nn.ReLU(),
                nn.MaxPool2d(2,2,0),)
        
        self.trm1 = nn.Sequential(
                nn.Conv2d(3,256,3,1,1),
                nn.MaxPool2d(2,2,0),
                nn.MaxPool2d(2,2,0),
                nn.MaxPool2d(2,2,0),
		nn.ReLU(),
                )

        self.trm2 = nn.Sequential(
                nn.Conv2d(256,512,3,1,1),
                nn.MaxPool2d(2,2,0), 
                nn.MaxPool2d(2,2,0),
		nn.ReLU(),
                )

        self.fc = nn.Sequential(
                nn.Linear( 512*4*4 , 4096 ),
                nn.ReLU(),
                nn.Linear(4096,4096),
                nn.ReLU(),
                nn.Linear(4096,12))

    def forward(self, x):
        # print(x[0])
        trm_x1 = self.trm1(x)
        out = self.cnn1(x)
        # print(out[0])
        out = self.cnn2(out) 
        # print(out[0]) 
        out = self.cnn3(out)
        trm_x2 = self.trm2(out)
        out = out + trm_x1
        # print(out[0]) 
        out = self.cnn4(out)
        # print(out[0]) 
        out = self.cnn5(out) + trm_x2
        # print(out[0]) 
        out = out.view(out.size(0),-1)
        #################################################################
        ########可透過print(xout.size())來得知最後一層的神經元數量########
        ##################################################################
        out = self.fc(out)
        return out

batch_size = 32
train_data = datasets.ImageFolder(path, transform=train_tfm)
print(train_data.class_to_idx)
#切分70%當作訓練集、30%當作驗證集
train_size = int(0.8 * len(train_data))
valid_size = len(train_data) - train_size

train_data, valid_data = torch.utils.data.random_split(train_data, [train_size, valid_size])
#Dataloader可以用Batch的方式訓練
train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,num_workers=2,shuffle=True, pin_memory=True)
valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size,num_workers=2,shuffle=True, pin_memory=True)

# "cuda" only when GPUs are available.
device = "cuda:1" if torch.cuda.is_available() else "cpu"

# The number of training epochs and patience.
n_epochs = 600
patience = 300 # If no improvement in 'patience' epochs, early stop

# Initialize a model, and put it on the device specified.
model = Residual_Network().to(device)
# if os.path.exists(f"{_exp_name}_best.ckpt"):
#     model.load_state_dict(torch.load(f"{_exp_name}_best.ckpt"))
#     print("is exists")
# For the classification task, we use cross-entropy as the measurement of performance.
criterion = nn.CrossEntropyLoss()

# Initialize optimizer, you may fine-tune some hyperparameters such as learning rate on your own.
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5) 

# Initialize trackers, these are not parameters and should not be changed
stale = 0
best_acc = 0
def show_history(epoch, valid_loss, valid_accs, train_loss, train_accs):
    epochs = [i for i in range(epoch+1)]
    plt.plot(epochs, train_loss, label="Train_Loss")
    plt.plot(epochs, valid_loss, label="Valid_Loss")
    plt.legend()
    plt.title("Loss_fig")
    plt.xlabel("epoch")
    plt.ylabel("Loss")
    plt.savefig("./Loss.png")
    plt.cla()
    
    plt.plot(epochs, train_accs, label="Train_acc")
    plt.plot(epochs, valid_accs, label="Valid_acc")
    plt.legend()
    plt.title("acc_fig")
    plt.xlabel("epoch")
    plt.ylabel("acc") 
    plt.savefig('./Acc.png')
    plt.cla()
train_loss = []
train_accs = []
valid_loss = []
valid_accs = []
for epoch in range(n_epochs):

    # ---------- Training ----------
    # Make sure the model is in train mode before training.
    model.train()

    # These are used to record information in training.
    
    train_loss_tmp = []
    train_accs_tmp = []
        
    cont = 0
    for batch in tqdm(train_loader):

        # A batch consists of image data and corresponding labels.
        imgs, labels = batch
        #imgs = imgs.half()
        #print(imgs.shape,labels.shape)

        # Forward the data. (Make sure data and model are on the same device.)
        logits = model(imgs.to(device))

        # Calculate the cross-entropy loss.
        # We don't need to apply softmax before computing cross-entropy as it is done automatically.
        loss = criterion(logits, labels.to(device))

        # Gradients stored in the parameters in the previous step should be cleared out first.
        optimizer.zero_grad()

        # Compute the gradients for parameters.
        loss.backward()

        # Clip the gradient norms for stable training.
        grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)

        # Update the parameters with computed gradients.
        optimizer.step()

        # Compute the accuracy for current batch.
        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()

        # Record the loss and accuracy.
        train_loss_tmp.append(loss.item())
        train_accs_tmp.append(acc.cpu())

    train_loss.append(sum(train_loss_tmp) / len(train_loss_tmp))
    train_accs.append(sum(train_accs_tmp) / len(train_accs_tmp))


    # Print the information.
    print(f"[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss[-1]:.5f}, acc = {train_accs[-1]:.5f}")

    # ---------- Validation ----------
    # Make sure the model is in eval mode so that some modules like dropout are disabled and work normally.
    model.eval()

    # These are used to record information in validation.

    valid_loss_tmp = []
    valid_accs_tmp = []

    # Iterate the validation set by batches.
    for batch in tqdm(valid_loader):
        # A batch consists of image data andcorresponding labels.
        imgs, labels = batch
        #imgs = imgs.half()

        # We don't need gradient in validation.
        # Using torch.no_grad() accelerates the forward process.
        with torch.no_grad():
            logits = model(imgs.to(device))

        # We can still compute the loss (but not the gradient).
        loss = criterion(logits, labels.to(device))

        # Compute the accuracy for current batch.
        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()

        # Record the loss and accuracy.
        valid_loss_tmp.append(loss.item())
        valid_accs_tmp.append(acc.cpu())
        #break

    # The average loss and accuracy for entire validation set is the average of the recorded values.
    valid_loss.append(sum(valid_loss_tmp) / len(valid_loss_tmp))
    valid_accs.append(sum(valid_accs_tmp) / len(valid_accs_tmp))
    

    show_history(epoch, valid_loss, valid_accs, train_loss, train_accs)

    # Print the information.
    print(f"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss[-1]:.5f}, acc = {valid_accs[-1]:.5f} epoch {epoch}")


    # update logs
    if valid_accs[-1] > best_acc:
        with open(f"./{_exp_name}_log.txt",'a') as fi:
            fi.write(f"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss[-1]:.5f}, acc = {valid_accs[-1]:.5f} -> best epoch {epoch}\n")

    else:
        with open(f"./{_exp_name}_log.txt",'a') as fi:
            fi.write(f"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss[-1]:.5f}, acc = {valid_accs[-1]:.5f}  epoch {epoch}\n")


    # save models
    if valid_accs[-1] > best_acc:
        print(f"Best model found at epoch {epoch}, saving model")
        torch.save(model.state_dict(), f"{_exp_name}_best.ckpt") # only save best to prevent output memory exceed error
        best_acc = valid_accs[-1]
        stale = 0
    else:
        stale += 1
        if stale > patience:
            print(f"No improvment {patience} consecutive epochs, early stopping")
            break
#t_l=train_loss.cpu()
#t_a=train_acc.cpu()
#v_l=valid_loss.cpu()
#v_a=valid_acc.cpu()



#train_acc.cpu()
#valid_loss.cpu()
#valid_acc.cpu()
#show_history()
